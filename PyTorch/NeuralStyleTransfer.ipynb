{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralStyleTransfer",
      "provenance": [],
      "authorship_tag": "ABX9TyO3keNgZ1kx/ZLtZtr+Drfx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varunbommagunta/Machine_Learning/blob/main/PyTorch/NeuralStyleTransfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOrvGCtsXsDE"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03x3ptu5aEv4"
      },
      "source": [
        "class VGG(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.required_features = ['0','5','10','19','28']\n",
        "    self.model = models.vgg19(pretrained = True).features[:29]\n",
        "  \n",
        "  def forward(self,x):\n",
        "    features = []\n",
        "    for layer_num,layer in enumerate(self.model):\n",
        "      x = layer(x)\n",
        "      if str(layer_num) in self.required_features:\n",
        "        features.append(x)\n",
        "    return features"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY1o7IAIazng"
      },
      "source": [
        "def load_image(img):\n",
        "  image = Image.open(img)\n",
        "  image = loader(image).unsqueeze(0)\n",
        "  return image.to(device)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZONvcMVNa-ep"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "imsize = 500"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWNIjIqObIxI"
      },
      "source": [
        "loader = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize((imsize,imsize)),\n",
        "     transforms.ToTensor()\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoOB0Pu6bSm0"
      },
      "source": [
        "original_img = load_image('/content/yoda.jpeg')\n",
        "style_img = load_image('/content/style.jpg')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwpWyjbLbolW"
      },
      "source": [
        "generated = original_img.clone().requires_grad_(True)\n",
        "model = VGG().to(device).eval()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McrqLuJFb2HU"
      },
      "source": [
        "total_steps = 1000\n",
        "learning_rate = 0.01\n",
        "alpha = 1\n",
        "beta = 0.05\n",
        "optimizer = optim.Adam([generated],lr = learning_rate)\n",
        "gen = ['a.png','b.png','c.png','d.png','e.png','f.png','g.png','h.png',\n",
        "       'i.png','j.png','k.png','l.png','m.png']\n",
        "i = 0"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0xQLKntc3P1"
      },
      "source": [
        "for step in range(total_steps):\n",
        "  generated_features = model(generated)\n",
        "  original_img_features = model(original_img)\n",
        "  style_features = model(style_img)\n",
        "\n",
        "  style_loss = original_loss = 0\n",
        "\n",
        "  for gen_feature,orig_feature,style_feature in zip(generated_features,original_img_features,style_features):\n",
        "    batch_size,channel,height,width = gen_feature.shape\n",
        "    original_loss += torch.mean((gen_feature - orig_feature)**2)\n",
        "\n",
        "    G = gen_feature.view(channel,height*width).mm(gen_feature.view(channel,height*width).t())\n",
        "    A = style_feature.view(channel, height * width).mm(style_feature.view(channel, height * width).t())\n",
        "    style_loss += torch.mean((G - A) ** 2)     \n",
        "  total_loss = alpha*original_loss + beta*style_loss\n",
        "  optimizer.zero_grad()\n",
        "  total_loss.backward()\n",
        "  optimizer.step()\n",
        "  if step%100==0:\n",
        "    print(total_loss)\n",
        "    save_image(generated,gen[i])\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjo6DSMPjI1a"
      },
      "source": [
        "l"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}